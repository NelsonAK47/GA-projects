{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import OpenCV\n",
    "import cv2\n",
    "\n",
    "#import pickle\n",
    "import pickle\n",
    "\n",
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#import numpy, pandas and m\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "\n",
    "#import os\n",
    "import os\n",
    "\n",
    "#import csv\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tensorflow Movenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.putText(frame, (int(kx), int(ky)), 4, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Edges and Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the pickled rf model\n",
    "with open('../Data/movenet_rf_model_left_right_dr_dl_3.pkl', 'rb') as f:\n",
    "    movenet_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing Functions for Angle Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get joint angles through 3 points on a body\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First point on a body\n",
    "    b = np.array(b) # Mid point on a body\n",
    "    c = np.array(c) # End point on a body\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360.0-angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get neck inclination angles\n",
    "def calculate_angle2(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2-y1)*(-y1)/ (m.sqrt((x2 - x1)**2 + (y2-y1)**2) *y1))\n",
    "    degree = int(180/m.pi)* theta\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use IP Webcam app (1920x1080 resolution)\n",
    "cap = cv2.VideoCapture('http://192.168.1.23:8080/video')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Resize image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192,320)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    try:\n",
    "        left_shoulder_x = keypoints_with_scores[0][5][1]\n",
    "        left_shoulder_y = keypoints_with_scores[0][5][0]\n",
    "        left_ear_x = keypoints_with_scores[0][3][1]\n",
    "        left_ear_y = keypoints_with_scores[0][3][0]\n",
    "        \n",
    "        right_shoulder_x = keypoints_with_scores[0][6][1]\n",
    "        right_shoulder_y = keypoints_with_scores[0][6][0]\n",
    "        right_ear_x = keypoints_with_scores[0][4][1]\n",
    "        right_ear_y = keypoints_with_scores[0][4][0]\n",
    "        \n",
    "        left_shoulder = [left_shoulder_x, left_shoulder_y]\n",
    "        \n",
    "        left_hip = [keypoints_with_scores[0][11][1], keypoints_with_scores[0][11][0]]\n",
    "        left_elbow = [keypoints_with_scores[0][7][1], keypoints_with_scores[0][7][0]]\n",
    "        left_knee = [keypoints_with_scores[0][13][1], keypoints_with_scores[0][13][0]]\n",
    "        left_ankle = [keypoints_with_scores[0][15][1], keypoints_with_scores[0][15][0]]\n",
    "        left_wrist = [keypoints_with_scores[0][9][1], keypoints_with_scores[0][9][0]]\n",
    "        left_ear = [keypoints_with_scores[0][3][1], keypoints_with_scores[0][3][0]]\n",
    "        \n",
    "        right_hip = [keypoints_with_scores[0][12][1], keypoints_with_scores[0][12][0]]\n",
    "        right_shoulder = [keypoints_with_scores[0][6][1], keypoints_with_scores[0][6][0]]\n",
    "        right_elbow = [keypoints_with_scores[0][8][1], keypoints_with_scores[0][8][0]]\n",
    "        right_knee = [keypoints_with_scores[0][14][1], keypoints_with_scores[0][14][0]]\n",
    "        right_ankle = [keypoints_with_scores[0][16][1], keypoints_with_scores[0][16][0]]\n",
    "        right_wrist = [keypoints_with_scores[0][10][1], keypoints_with_scores[0][10][0]]\n",
    "        right_ear = [keypoints_with_scores[0][5][1], keypoints_with_scores[0][5][0]]\n",
    "        \n",
    "        neck_inclination = calculate_angle2(left_shoulder_x, left_shoulder_y, left_ear_x, left_ear_y)\n",
    "        \n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        #left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        left_bicep_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        \n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        #right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        right_bicep_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        #print(left_bicep_angle)\n",
    "        #print(neck_inclination)\n",
    "        #print(left_shoulder)\n",
    "        cv2.putText(frame , str(int(neck_inclination)), tuple(np.multiply(left_shoulder, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_hip_angle)), tuple(np.multiply(left_hip, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, str(int(left_knee_angle)), tuple(np.multiply(left_knee, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_bicep_angle)), tuple(np.multiply(left_elbow, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Export coordinates\n",
    "\n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n",
    "    \n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('http://192.168.1.23:8080/video')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Resize imageq\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192,320)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    try:\n",
    "        left_shoulder_x = keypoints_with_scores[0][5][1]\n",
    "        left_shoulder_y = keypoints_with_scores[0][5][0]\n",
    "        left_ear_x = keypoints_with_scores[0][3][1]\n",
    "        left_ear_y = keypoints_with_scores[0][3][0]\n",
    "        \n",
    "        right_shoulder_x = keypoints_with_scores[0][6][1]\n",
    "        right_shoulder_y = keypoints_with_scores[0][6][0]\n",
    "        right_ear_x = keypoints_with_scores[0][4][1]\n",
    "        right_ear_y = keypoints_with_scores[0][4][0]\n",
    "        \n",
    "        left_shoulder = [left_shoulder_x, left_shoulder_y]\n",
    "        \n",
    "        left_hip = [keypoints_with_scores[0][11][1], keypoints_with_scores[0][11][0]]\n",
    "        left_elbow = [keypoints_with_scores[0][7][1], keypoints_with_scores[0][7][0]]\n",
    "        left_knee = [keypoints_with_scores[0][13][1], keypoints_with_scores[0][13][0]]\n",
    "        left_ankle = [keypoints_with_scores[0][15][1], keypoints_with_scores[0][15][0]]\n",
    "        left_wrist = [keypoints_with_scores[0][9][1], keypoints_with_scores[0][9][0]]\n",
    "        left_ear = [keypoints_with_scores[0][3][1], keypoints_with_scores[0][3][0]]\n",
    "        \n",
    "        right_hip = [keypoints_with_scores[0][12][1], keypoints_with_scores[0][12][0]]\n",
    "        right_shoulder = [keypoints_with_scores[0][6][1], keypoints_with_scores[0][6][0]]\n",
    "        right_elbow = [keypoints_with_scores[0][8][1], keypoints_with_scores[0][8][0]]\n",
    "        right_knee = [keypoints_with_scores[0][14][1], keypoints_with_scores[0][14][0]]\n",
    "        right_ankle = [keypoints_with_scores[0][16][1], keypoints_with_scores[0][16][0]]\n",
    "        right_wrist = [keypoints_with_scores[0][10][1], keypoints_with_scores[0][10][0]]\n",
    "        right_ear = [keypoints_with_scores[0][5][1], keypoints_with_scores[0][5][0]]\n",
    "        \n",
    "        neck_inclination = calculate_angle2(left_shoulder_x, left_shoulder_y, left_ear_x, left_ear_y)\n",
    "        \n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        #left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        left_bicep_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        \n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        #right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        right_bicep_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        #print(left_bicep_angle)\n",
    "        #print(neck_inclination)\n",
    "        #print(left_shoulder)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Export coordinates\n",
    "    try:\n",
    "        pose_row =list(keypoints_with_scores[0].flatten())\n",
    "        \n",
    "        left_bicep_row = list(np.array(left_bicep_angle).flatten())\n",
    "        left_hip_row = list(np.array(left_hip_angle).flatten())\n",
    "        \n",
    "        right_bicep_row = list(np.array(right_bicep_angle).flatten())\n",
    "        right_hip_row = list(np.array(right_hip_angle).flatten())\n",
    "        \n",
    "        neck_inclination_row = list(np.array(neck_inclination).flatten())\n",
    "        \n",
    "        row = neck_inclination_row + left_hip_row + left_bicep_row + right_hip_row + right_bicep_row + pose_row\n",
    "        #row.insert(0,class_name)\n",
    "        \n",
    "        #with open('coords_movenet_lieback.csv', mode ='a', newline ='') as f:\n",
    "                #csv_writer = csv.writer(f, delimiter =',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                #csv_writer.writerow(row)\n",
    "                \n",
    "    #Make Detections and Predictions\n",
    "        X = pd.DataFrame([row])\n",
    "        movenet_class = movenet_model.predict(X)[0]\n",
    "        movenet_prob = movenet_model.predict_proba(X)[0]\n",
    "        #print(movenet_class, movenet_prob)\n",
    "        \n",
    "    # Get status box\n",
    "        cv2.rectangle(frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "        \n",
    "    # Display Class\n",
    "        cv2.putText(frame, 'CLASS'\n",
    "                    , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, movenet_class.split(' ')[0]\n",
    "                    , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Display Probability\n",
    "        cv2.putText(frame, 'PROB'\n",
    "                    , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(round(movenet_prob[np.argmax(movenet_prob)],2))\n",
    "                    , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)   \n",
    "        \n",
    "    #Visualise\n",
    "        cv2.putText(frame , str(int(neck_inclination)), tuple(np.multiply(left_shoulder, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_hip_angle)), tuple(np.multiply(left_hip, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, str(int(left_knee_angle)), tuple(np.multiply(left_knee, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_bicep_angle)), tuple(np.multiply(left_elbow, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n",
    "    \n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('http://192.168.1.23:8080/video')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Resize imageq\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192,320)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    try:\n",
    "        left_shoulder_x = keypoints_with_scores[0][5][1]\n",
    "        left_shoulder_y = keypoints_with_scores[0][5][0]\n",
    "        left_ear_x = keypoints_with_scores[0][3][1]\n",
    "        left_ear_y = keypoints_with_scores[0][3][0]\n",
    "        \n",
    "        right_shoulder_x = keypoints_with_scores[0][6][1]\n",
    "        right_shoulder_y = keypoints_with_scores[0][6][0]\n",
    "        right_ear_x = keypoints_with_scores[0][4][1]\n",
    "        right_ear_y = keypoints_with_scores[0][4][0]\n",
    "        \n",
    "        left_shoulder = [left_shoulder_x, left_shoulder_y]\n",
    "        \n",
    "        left_hip = [keypoints_with_scores[0][11][1], keypoints_with_scores[0][11][0]]\n",
    "        left_elbow = [keypoints_with_scores[0][7][1], keypoints_with_scores[0][7][0]]\n",
    "        left_knee = [keypoints_with_scores[0][13][1], keypoints_with_scores[0][13][0]]\n",
    "        left_ankle = [keypoints_with_scores[0][15][1], keypoints_with_scores[0][15][0]]\n",
    "        left_wrist = [keypoints_with_scores[0][9][1], keypoints_with_scores[0][9][0]]\n",
    "        left_ear = [keypoints_with_scores[0][3][1], keypoints_with_scores[0][3][0]]\n",
    "        \n",
    "        right_hip = [keypoints_with_scores[0][12][1], keypoints_with_scores[0][12][0]]\n",
    "        right_shoulder = [keypoints_with_scores[0][6][1], keypoints_with_scores[0][6][0]]\n",
    "        right_elbow = [keypoints_with_scores[0][8][1], keypoints_with_scores[0][8][0]]\n",
    "        right_knee = [keypoints_with_scores[0][14][1], keypoints_with_scores[0][14][0]]\n",
    "        right_ankle = [keypoints_with_scores[0][16][1], keypoints_with_scores[0][16][0]]\n",
    "        right_wrist = [keypoints_with_scores[0][10][1], keypoints_with_scores[0][10][0]]\n",
    "        right_ear = [keypoints_with_scores[0][5][1], keypoints_with_scores[0][5][0]]\n",
    "        \n",
    "        neck_inclination = calculate_angle2(left_shoulder_x, left_shoulder_y, left_ear_x, left_ear_y)\n",
    "        \n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        #left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        left_bicep_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        \n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        #right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        right_bicep_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        #print(left_bicep_angle)\n",
    "        #print(neck_inclination)\n",
    "        #print(left_shoulder)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Export coordinates\n",
    "    try:\n",
    "        pose_row =list(keypoints_with_scores[0].flatten())\n",
    "        \n",
    "        left_bicep_row = list(np.array(left_bicep_angle).flatten())\n",
    "        left_hip_row = list(np.array(left_hip_angle).flatten())\n",
    "        \n",
    "        right_bicep_row = list(np.array(right_bicep_angle).flatten())\n",
    "        right_hip_row = list(np.array(right_hip_angle).flatten())\n",
    "        \n",
    "        neck_inclination_row = list(np.array(neck_inclination).flatten())\n",
    "        \n",
    "        row = neck_inclination_row + left_hip_row + left_bicep_row + right_hip_row + right_bicep_row + pose_row\n",
    "        #row.insert(0,class_name)\n",
    "        \n",
    "        #with open('coords_movenet_lieback.csv', mode ='a', newline ='') as f:\n",
    "                #csv_writer = csv.writer(f, delimiter =',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                #csv_writer.writerow(row)\n",
    "                \n",
    "    #Make Detections and Predictions\n",
    "        X = pd.DataFrame([row])\n",
    "        movenet_class = movenet_model.predict(X)[0]\n",
    "        movenet_prob = movenet_model.predict_proba(X)[0]\n",
    "        #print(movenet_class, movenet_prob)\n",
    "        \n",
    "    # Get status box\n",
    "        cv2.rectangle(frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "        \n",
    "    # Display Class\n",
    "        cv2.putText(frame, 'CLASS'\n",
    "                    , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, movenet_class.split(' ')[0]\n",
    "                    , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Display Probability\n",
    "        cv2.putText(frame, 'PROB'\n",
    "                    , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(round(movenet_prob[np.argmax(movenet_prob)],2))\n",
    "                    , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)   \n",
    "        \n",
    "    #Visualise\n",
    "        cv2.putText(frame , str(int(neck_inclination)), tuple(np.multiply(left_shoulder, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_hip_angle)), tuple(np.multiply(left_hip, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, str(int(left_knee_angle)), tuple(np.multiply(left_knee, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_bicep_angle)), tuple(np.multiply(left_elbow, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n",
    "    \n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('http://192.168.1.23:8080/video')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Resize image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 192,320)\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detection section\n",
    "    results = movenet(input_img)\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "    try:\n",
    "        left_shoulder_x = keypoints_with_scores[0][5][1]\n",
    "        left_shoulder_y = keypoints_with_scores[0][5][0]\n",
    "        left_ear_x = keypoints_with_scores[0][3][1]\n",
    "        left_ear_y = keypoints_with_scores[0][3][0]\n",
    "        \n",
    "        right_shoulder_x = keypoints_with_scores[0][6][1]\n",
    "        right_shoulder_y = keypoints_with_scores[0][6][0]\n",
    "        right_ear_x = keypoints_with_scores[0][4][1]\n",
    "        right_ear_y = keypoints_with_scores[0][4][0]\n",
    "        \n",
    "        left_shoulder = [left_shoulder_x, left_shoulder_y]\n",
    "        \n",
    "        left_hip = [keypoints_with_scores[0][11][1], keypoints_with_scores[0][11][0]]\n",
    "        left_elbow = [keypoints_with_scores[0][7][1], keypoints_with_scores[0][7][0]]\n",
    "        left_knee = [keypoints_with_scores[0][13][1], keypoints_with_scores[0][13][0]]\n",
    "        left_ankle = [keypoints_with_scores[0][15][1], keypoints_with_scores[0][15][0]]\n",
    "        left_wrist = [keypoints_with_scores[0][9][1], keypoints_with_scores[0][9][0]]\n",
    "        left_ear = [keypoints_with_scores[0][3][1], keypoints_with_scores[0][3][0]]\n",
    "        \n",
    "        right_hip = [keypoints_with_scores[0][12][1], keypoints_with_scores[0][12][0]]\n",
    "        right_shoulder = [keypoints_with_scores[0][6][1], keypoints_with_scores[0][6][0]]\n",
    "        right_elbow = [keypoints_with_scores[0][8][1], keypoints_with_scores[0][8][0]]\n",
    "        right_knee = [keypoints_with_scores[0][14][1], keypoints_with_scores[0][14][0]]\n",
    "        right_ankle = [keypoints_with_scores[0][16][1], keypoints_with_scores[0][16][0]]\n",
    "        right_wrist = [keypoints_with_scores[0][10][1], keypoints_with_scores[0][10][0]]\n",
    "        right_ear = [keypoints_with_scores[0][5][1], keypoints_with_scores[0][5][0]]\n",
    "        \n",
    "        neck_inclination = calculate_angle2(left_shoulder_x, left_shoulder_y, left_ear_x, left_ear_y)\n",
    "        \n",
    "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "        #left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "        left_bicep_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        \n",
    "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "        #right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "        right_bicep_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        #print(left_bicep_angle)\n",
    "        #print(neck_inclination)\n",
    "        #print(left_shoulder)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Export coordinates\n",
    "    try:\n",
    "        pose_row =list(keypoints_with_scores[0].flatten())\n",
    "        \n",
    "        left_bicep_row = list(np.array(left_bicep_angle).flatten())\n",
    "        left_hip_row = list(np.array(left_hip_angle).flatten())\n",
    "        \n",
    "        right_bicep_row = list(np.array(right_bicep_angle).flatten())\n",
    "        right_hip_row = list(np.array(right_hip_angle).flatten())\n",
    "        \n",
    "        neck_inclination_row = list(np.array(neck_inclination).flatten())\n",
    "        \n",
    "        row = neck_inclination_row + left_hip_row + left_bicep_row + right_hip_row + right_bicep_row + pose_row\n",
    "        #row.insert(0,class_name)\n",
    "        \n",
    "        #with open('coords_movenet_lieback.csv', mode ='a', newline ='') as f:\n",
    "                #csv_writer = csv.writer(f, delimiter =',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                #csv_writer.writerow(row)\n",
    "                \n",
    "    #Make Detections and Predictions\n",
    "        X = pd.DataFrame([row])\n",
    "        movenet_class = movenet_model.predict(X)[0]\n",
    "        movenet_prob = movenet_model.predict_proba(X)[0]\n",
    "        #print(movenet_class, movenet_prob)\n",
    "        \n",
    "    # Get status box\n",
    "        cv2.rectangle(frame, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "        cv2.rectangle(frame, (0,1000), (250, 1100), (245, 117, 16), -1)\n",
    "        cv2.rectangle(frame, (2000,1000), (1550, 1100), (245, 117, 16), -1)\n",
    "            \n",
    "#Display Good vs Bad Posture\n",
    "        if movenet_class == 'straight':\n",
    "            bad_posture = 0\n",
    "            good_posture += 1\n",
    "            cv2.putText(frame, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, movenet_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Good Posture'\n",
    "                        , (15,1040), cv2.FONT_HERSHEY_SIMPLEX,  1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(round(movenet_prob[np.argmax(movenet_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            good_posture = 0\n",
    "            bad_posture += 1 \n",
    "            cv2.putText(frame, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, movenet_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'Bad Posture'\n",
    "                        , (15,1040), cv2.FONT_HERSHEY_SIMPLEX,  1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, str(round(movenet_prob[np.argmax(movenet_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "     \n",
    "    #Getting pose time\n",
    "        good_time_posture = (2.2 / fps) * good_posture\n",
    "        bad_time_posture = (2.2 / fps) * bad_posture\n",
    "            \n",
    "        if good_time_posture > 0:\n",
    "            good_time_posture_print = 'Good Posture Time: ' + str(round(good_time_posture,1)) + 's'\n",
    "            cv2.putText(frame, good_time_posture_print\n",
    "                        , (1600,1040), cv2.FONT_HERSHEY_SIMPLEX,  0.7, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            bad_time_posture_print = 'Bad Posture Time: ' + str(round(bad_time_posture,1)) + 's'\n",
    "            cv2.putText(frame, bad_time_posture_print\n",
    "                        , (1600,1040), cv2.FONT_HERSHEY_SIMPLEX,  0.7, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        if bad_time_posture > 20:\n",
    "            sendWarning()\n",
    "        \n",
    "    #Visualise\n",
    "        cv2.putText(frame , str(int(neck_inclination)), tuple(np.multiply(left_shoulder, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_hip_angle)), tuple(np.multiply(left_hip, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        #cv2.putText(frame, str(int(left_knee_angle)), tuple(np.multiply(left_knee, [1850,800]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, str(int(left_bicep_angle)), tuple(np.multiply(left_elbow, [1850,1100]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Render keypoints \n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3)\n",
    "    \n",
    "    cv2.imshow('LiveCam Feed', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Limitation and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best models (Random Forest Classifier and Extra Tree Classifier from PyCaret) are able to detect various pre-determined postures based on pose estimation model for both webcam and sidecam. Summary of models are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of models are as follows (for webcam):**\n",
    "\n",
    "|Models|Validation Accuracy|Mean F1 Score of 5 Postures|\n",
    "|---|:--:|:--:|\n",
    "|Logistic Regression|99.8%|99.8%|\n",
    "|Ridge Classification|97.2%|97.2%|\n",
    "|Random Forest Classifier|99.6%|99.6%|\n",
    "|Gradient Boosting Classifier|99.6%|99.8%|\n",
    "|Adaptive Boosting (ADA) Classifier|53.2%|45.1%|\n",
    "|Decision Tree Classifier|98.6%|98.6%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of models are as follows (for sidecam):**\n",
    "\n",
    "|Models|Validation Accuracy|Mean F1 Score of 5 Postures|\n",
    "|---|:--:|:--:|\n",
    "|Logistic Regression|98.8%|98.8%|\n",
    "|Ridge Classification|95.2%|94.5%|\n",
    "|Random Forest Classifier|99.6%|99.1%|\n",
    "|Gradient Boosting Classifier|99.5%|99%|\n",
    "|Adaptive Boosting (ADA) Classifier|59.4%|57.7%|\n",
    "|Decision Tree Classifier|97.4%|97%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although current model has performed well under real live camera, it has some limitations:\n",
    "    \n",
    "1. Model is currently limited to identifying straight, slouched/hunched, slouched/hunched + roundshoulders, uneven shoulder(webcam) and lieback. However, there are many combined postures such as cross legs, butterfly sit posture, knee angle detection, etc. In addition, there are many more complex postures and alignments such as monitor alignment, table/chair height optimisation, etc.\n",
    "\n",
    "\n",
    "2. Current models are trained based on limited own dataset with certain angles and camera placements. In the future, more cameras can be used to train to create more robust models to cater for all environments.\n",
    "\n",
    "\n",
    "3. Model is only capable of reminding bad postures after 15 secs through audio. However, in real life scenario, it is better to give live angle recommendations for the users to adjust to straight posture.\n",
    "\n",
    "\n",
    " All in all, future improvements can include :\n",
    " - More complex postures specifically legs joints as these body parts also affect sitting ergonomics.\n",
    " \n",
    " \n",
    " - Utilise more cameras to cover all camera angles/placements for model training. Thus, it will be able to create a much robust model at different placements when deployed to offices/homes.\n",
    " \n",
    " \n",
    " - Train more models to cater for 2 or more people in a frame.\n",
    " \n",
    " \n",
    " - Explore deep learning models (CNN or RNN) for dataset training.\n",
    " \n",
    " \n",
    " - It is also possible to use object detection models such as Mask R-CNN or YOLO to detect monitors, chairs and tables to ultimately give recommendations for best alignments/placements and heights for each workstation.\n",
    " \n",
    " \n",
    " - Use Tkinter to develop GUI app for posture record and recommendations to correct postures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
