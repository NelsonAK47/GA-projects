{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a continuation of Capstone-AI-Ergonomics-Webcam-Model-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, trained models will be imported and visualised in webcam LIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import OpenCV\n",
    "import cv2\n",
    "\n",
    "#import pickle\n",
    "import pickle\n",
    "\n",
    "#import mediapipe\n",
    "import mediapipe as mp\n",
    "\n",
    "#import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import os\n",
    "import os\n",
    "\n",
    "#import cvzone\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "\n",
    "#import csv\n",
    "import csv\n",
    "\n",
    "#import playsound\n",
    "from playsound import playsound\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use mediapipe to draw and render detections in opencv\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_face = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the pickled rf model\n",
    "with open('../Data/new_webcam_rf_model_3.pkl', 'rb') as f:\n",
    "    webcam_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.65, min_tracking_confidence=0.65) as holistic:\n",
    "    detector = FaceMeshDetector(maxFaces=1)\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        resized=cv2.resize(frame,(800,600))\n",
    "        resized, faces = detector.findFaceMesh(resized, draw = False)\n",
    "    \n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            left_eye = face[145]\n",
    "            right_eye = face[374]\n",
    "            #cv2.line(resized, left_eye, right_eye, (0,200,0),3)\n",
    "            #cv2.circle(resized, left_eye,5,(255,0,255),cv2.FILLED)\n",
    "            #cv2.circle(resized, right_eye,5,(255,0,255),cv2.FILLED)\n",
    "            eye_distance_pixel,_ = detector.findDistance(left_eye,right_eye)\n",
    "            #print(eye_distance_pixel)\n",
    "        \n",
    "            #Find focal length\n",
    "            eye_distance_cm = 6.3\n",
    "            #distance = 50\n",
    "            #f =(eye_distance_pixel * distance)/eye_distance_cm\n",
    "            #print(f)\n",
    "        \n",
    "            f = 580\n",
    "            distance = (eye_distance_cm * f)/ eye_distance_pixel\n",
    "        \n",
    "            cv2.putText(resized, f'Eye Distance to Webcam: {int(distance)}cm', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "         \n",
    "    #Recolor image to RGB\n",
    "        image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "    #Make detections\n",
    "        results = holistic.process(image)\n",
    "    \n",
    "    #Recolor image back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        \n",
    "    #Draw Pose Detections    \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "    \n",
    "        cv2.imshow('Webcam Feed', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [800,600]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 328)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords[1]+5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.65, min_tracking_confidence=0.65) as holistic:\n",
    "    detector = FaceMeshDetector(maxFaces=1)\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        resized=cv2.resize(frame,(800,600))\n",
    "        resized, faces = detector.findFaceMesh(resized, draw = False)\n",
    "    \n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            left_eye = face[145]\n",
    "            right_eye = face[374]\n",
    "            #cv2.line(resized, left_eye, right_eye, (0,200,0),3)\n",
    "            #cv2.circle(resized, left_eye,5,(255,0,255),cv2.FILLED)\n",
    "            #cv2.circle(resized, right_eye,5,(255,0,255),cv2.FILLED)\n",
    "            eye_distance_pixel,_ = detector.findDistance(left_eye,right_eye)\n",
    "            #print(eye_distance_pixel)\n",
    "        \n",
    "            #Find focal length\n",
    "            eye_distance_cm = 6.3\n",
    "            #distance = 50\n",
    "            #f =(eye_distance_pixel * distance)/eye_distance_cm\n",
    "            #print(f)\n",
    "        \n",
    "            f = 580\n",
    "            distance = (eye_distance_cm * f)/ eye_distance_pixel\n",
    "        \n",
    "            #cv2.putText(resized, f'Eye Distance to Webcam: {int(distance)}cm', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "    #Recolor image to RGB\n",
    "        image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "    #Make detections\n",
    "        results = holistic.process(image)\n",
    "    \n",
    "    #Recolor image back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        \n",
    "    #Draw Pose Detections    \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "        \n",
    "    #Export coordinates\n",
    "        try:\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            distance_row = list(np.array(distance).flatten())\n",
    "            \n",
    "            row = distance_row + pose_row\n",
    "            #row.insert(0,posture_name)\n",
    "            \n",
    "            #with open('coords_webcam_uneven_shoulder.csv', mode ='a', newline ='') as f:\n",
    "                #csv_writer = csv.writer(f, delimiter =',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                #csv_writer.writerow(row)\n",
    "                \n",
    "    #Make Detections and Predictions\n",
    "            X = pd.DataFrame([row])\n",
    "            webcam_class = webcam_model.predict(X)[0]\n",
    "            webcam_prob = webcam_model.predict_proba(X)[0]\n",
    "            #print(webcam_class, webcam_prob)\n",
    "            \n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [800,600]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(webcam_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, webcam_class, coords,cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "    # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, webcam_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(webcam_prob[np.argmax(webcam_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)   \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        cv2.imshow('Live Cam', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Model Predictions, Posture Time and Audio Reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.65, min_tracking_confidence=0.65) as holistic:\n",
    "    detector = FaceMeshDetector(maxFaces=1)\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        resized=cv2.resize(frame,(800,600))\n",
    "        resized, faces = detector.findFaceMesh(resized, draw = False)\n",
    "    \n",
    "        if faces:\n",
    "            face = faces[0]\n",
    "            left_eye = face[145]\n",
    "            right_eye = face[374]\n",
    "            #cv2.line(resized, left_eye, right_eye, (0,200,0),3)\n",
    "            #cv2.circle(resized, left_eye,5,(255,0,255),cv2.FILLED)\n",
    "            #cv2.circle(resized, right_eye,5,(255,0,255),cv2.FILLED)\n",
    "            eye_distance_pixel,_ = detector.findDistance(left_eye,right_eye)\n",
    "            #print(eye_distance_pixel)\n",
    "        \n",
    "            #Find focal length\n",
    "            #eye_distance_cm = 6.3\n",
    "            #distance = 50\n",
    "            #f =(eye_distance_pixel * distance)/eye_distance_cm\n",
    "            #print(f)\n",
    "        \n",
    "            f = 580\n",
    "            distance = (eye_distance_cm * f)/ eye_distance_pixel\n",
    "        \n",
    "            #cv2.putText(resized, f'Eye Distance to Webcam: {int(distance)}cm', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "    #Recolor image to RGB\n",
    "        image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "    #Make detections\n",
    "        results = holistic.process(image)\n",
    "    \n",
    "    #Recolor image back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        \n",
    "    #Draw Pose Detections    \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "        \n",
    "    #Export coordinates\n",
    "        try:\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            distance_row = list(np.array(distance).flatten())\n",
    "            \n",
    "            row = distance_row + pose_row\n",
    "            #row.insert(0,posture_name)\n",
    "            \n",
    "            #with open('coords_webcam_uneven_shoulder.csv', mode ='a', newline ='') as f:\n",
    "                #csv_writer = csv.writer(f, delimiter =',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                #csv_writer.writerow(row)\n",
    "                \n",
    "    #Make Detections and Predictions\n",
    "            X = pd.DataFrame([row])\n",
    "            webcam_class = webcam_model.predict(X)[0]\n",
    "            webcam_prob = webcam_model.predict_proba(X)[0]\n",
    "            #print(webcam_class, webcam_prob)\n",
    "            \n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [800,600]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(webcam_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, webcam_class, coords,cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Get status box\n",
    "            cv2.rectangle(image, (0,0), (300, 60), (245, 117, 16), -1)\n",
    "            cv2.rectangle(image, (0,600), (250, 560), (245, 117, 16), -1)\n",
    "            cv2.rectangle(image, (800,600), (550, 570), (245, 117, 16), -1)\n",
    "            cv2.rectangle(image, (490,0), (800, 30), (245, 117, 16), -1)\n",
    "    \n",
    "    #Display Good vs Bad Posture\n",
    "            if webcam_class == 'straight':\n",
    "                bad_posture = 0\n",
    "                good_posture += 1\n",
    "                cv2.putText(image, 'CLASS'\n",
    "                            , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, webcam_class.split(' ')[0]\n",
    "                            , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Good Posture'\n",
    "                            , (15,590), cv2.FONT_HERSHEY_SIMPLEX,  1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'PROB'\n",
    "                            , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(round(webcam_prob[np.argmax(webcam_prob)],2))\n",
    "                            , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'Eye Distance to Webcam: {int(distance)}cm'\n",
    "                            , (490,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (127,233,100), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                good_posture = 0\n",
    "                bad_posture += 1 \n",
    "                cv2.putText(image, 'CLASS'\n",
    "                            , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, webcam_class.split(' ')[0]\n",
    "                            , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Bad Posture'\n",
    "                            , (15,590), cv2.FONT_HERSHEY_SIMPLEX,  1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'PROB'\n",
    "                            , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(round(webcam_prob[np.argmax(webcam_prob)],2))\n",
    "                            , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, f'Eye Distance to Webcam: {int(distance)}cm'\n",
    "                            , (490,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50,50,255), 2, cv2.LINE_AA)\n",
    "     \n",
    "    #Getting pose time\n",
    "            good_time_posture = (3 / fps) * good_posture\n",
    "            bad_time_posture = (3 / fps) * bad_posture\n",
    "            \n",
    "            if good_time_posture > 0:\n",
    "                good_time_posture_print = 'Good Posture Time: ' + str(round(good_time_posture,1)) + 's'\n",
    "                cv2.putText(image, good_time_posture_print\n",
    "                            , (560,590), cv2.FONT_HERSHEY_SIMPLEX,  0.6, (127, 233, 100), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                bad_time_posture_print = 'Bad Posture Time: ' + str(round(bad_time_posture,1)) + 's'\n",
    "                cv2.putText(image, bad_time_posture_print\n",
    "                            , (560,590), cv2.FONT_HERSHEY_SIMPLEX,  0.6, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            if bad_time_posture > 15:\n",
    "                playsound('../Data/Audio file webcam.mp3')\n",
    "                bad_time_posture_print = 'Bad Posture Time: ' + str(round(bad_time_posture,1)) + 's'\n",
    "                cv2.putText(image, bad_time_posture_print\n",
    "                            , (560,590), cv2.FONT_HERSHEY_SIMPLEX,  0.6, (50, 50, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        cv2.imshow('Live Cam', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
